{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b73abc2",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f538a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix, precision_score, recall_score, auc,roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f0461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20001, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urls</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mp3raid.com/music/krizz_kaliko.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bopsecrets.org/rexroth/cr/1.htm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.garage-pirenne.be/index.php?option=...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://adventure-nicaragua.net/index.php?optio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://buzzfil.net/m/show-art/ils-etaient-loin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                urls  type\n",
       "0                mp3raid.com/music/krizz_kaliko.html     0\n",
       "1                    bopsecrets.org/rexroth/cr/1.htm     0\n",
       "2  http://www.garage-pirenne.be/index.php?option=...     1\n",
       "3  http://adventure-nicaragua.net/index.php?optio...     1\n",
       "4  http://buzzfil.net/m/show-art/ils-etaient-loin...     0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:/SASTRA UNIVERSITY/Mini_Project/testing.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bd96b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14682\n",
       "1     5319\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410d47f4",
   "metadata": {},
   "source": [
    "# IP Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1488955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def having_ip_address(urls):\n",
    "    match = re.search(\n",
    "        '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n",
    "        '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  # IPv4\n",
    "        '((0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\/)' # IPv4 in hexadecimal\n",
    "        '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}', urls)  # Ipv6\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['ip_in_URL'] = df['urls'].apply(lambda i: having_ip_address(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2503e1",
   "metadata": {},
   "source": [
    "# Random words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "504897c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_random_words(urls):\n",
    "    li1 = re.findall(\"[A-Za-z]+\",urls)\n",
    "    return len(li1)\n",
    "df['random_words'] = df['urls'].apply(lambda i: count_random_words(i))\n",
    "\n",
    "def avg_len_random(urls):\n",
    "    sum = 0\n",
    "    li2 = re.findall(\"[A-Za-z]+\",urls)\n",
    "    for u in li2:\n",
    "        sum = sum + len(u)\n",
    "    return (sum/len(li2))\n",
    "\n",
    "df['avg_len_random_words'] = df['urls'].apply(lambda i: avg_len_random(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498a573c",
   "metadata": {},
   "source": [
    "# English Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3672b0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b4f92d00e0481392c94410b42eebcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/20001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f557b3142f6444cb8aecedd4afbf130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/20001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from enchant import Dict\n",
    "import swifter\n",
    "d = Dict(\"en_US\")\n",
    "pattern = re.compile(\"[A-Za-z]+\") \n",
    "\n",
    "def count_english_words(urls): \n",
    "    li1 = pattern.findall(urls) \n",
    "    return sum([1 for word in li1 if d.check(word)]) \n",
    "\n",
    "def avg_len_english(urls): \n",
    "    li2 = pattern.findall(urls) \n",
    "    english_words = [u for u in li2 if d.check(u)] \n",
    "    return sum(map(len, english_words)) / len(english_words) if len(english_words)!=0 else 0\n",
    "\n",
    "df['english_words'] = df['urls'].swifter.apply(count_english_words)\n",
    "df['avg_len_english_words'] = df['urls'].swifter.apply(avg_len_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da737f1f",
   "metadata": {},
   "source": [
    "# Lexical features (;, &, http, https, _, #, @, url_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d73627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['http_in_URL'] = df['urls'].apply(lambda i: i.count('http'))\n",
    "df['semicolon_in_URL'] = df['urls'].apply(lambda i: i.count(';'))\n",
    "df['AND_in_URL'] = df['urls'].apply(lambda i: i.count('&'))\n",
    "df['URL_length'] = df['urls'].apply(lambda i: len(str(i)))\n",
    "\n",
    "df['underscore'] = df['urls'].apply(lambda i: i.count('_'))\n",
    "df['//'] = df['urls'].apply(lambda i: i.count('//'))\n",
    "df['@'] = df['urls'].apply(lambda i: i.count('@'))\n",
    "df['hash'] = df['urls'].apply(lambda i: i.count('#'))\n",
    "df['https'] = df['urls'].apply(lambda i: i.count('https'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cc9c20",
   "metadata": {},
   "source": [
    "# Letters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e9eabc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_count(url):\n",
    "    letters = 0\n",
    "    for i in url:\n",
    "        if i.isalpha():\n",
    "            letters = letters + 1\n",
    "    return letters\n",
    "df['alphabets_in_URL']= df['urls'].apply(lambda i: letter_count(i))\n",
    "\n",
    "def uppercase_count(url):\n",
    "    letters1 = 0\n",
    "    for i in url:\n",
    "        if i>='A' and i<='Z':\n",
    "            letters1 = letters1 + 1\n",
    "    return letters1\n",
    "df['uppercase_letters_inURL']= df['urls'].apply(lambda i: uppercase_count(i))\n",
    "\n",
    "def lowercase_count(url):\n",
    "    letters2 = 0\n",
    "    for i in url:\n",
    "        if i>='a' and i<='z':\n",
    "            letters2 = letters2 + 1\n",
    "    return letters2\n",
    "df['lowercase_letters_inURL']= df['urls'].apply(lambda i: lowercase_count(i))\n",
    "\n",
    "def uppercase_ratio(url):\n",
    "    url_len = len(str(url))\n",
    "    letters1 = 0\n",
    "    for i in url:\n",
    "        if i>='A' and i<='Z':\n",
    "            letters1 = letters1 + 1\n",
    "    return (letters1/url_len)\n",
    "df['uppercase_letters_ratio_inURL']= df['urls'].apply(lambda i: uppercase_ratio(i))\n",
    "\n",
    "def lowercase_ratio(url):\n",
    "    url_len = len(str(url))\n",
    "    letters2 = 0\n",
    "    for i in url:\n",
    "        if i>='a' and i<='z':\n",
    "            letters2 = letters2 + 1\n",
    "    return (letters2/url_len)\n",
    "df['lowercase_letters_ratio_inURL']= df['urls'].apply(lambda i: lowercase_ratio(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b31dd2a",
   "metadata": {},
   "source": [
    "# special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46b97685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spl_char_count(url):\n",
    "    url_len = len(str(url))\n",
    "    chars = 0\n",
    "    for i in url:\n",
    "        if i=='!' or i=='@' or i=='#' or i=='%' or i=='^' or i=='&' or i=='*' or i=='(' or i==')':\n",
    "            chars = chars + 1\n",
    "    return chars\n",
    "df['Special_char_in_URL']= df['urls'].apply(lambda i: spl_char_count(i))\n",
    "\n",
    "def spl_char_ratio(url):\n",
    "    url_len = len(str(url))\n",
    "    chars = 0\n",
    "    for i in url:\n",
    "        if i=='!' or i=='@' or i=='#' or i=='%' or i=='^' or i=='&' or i=='*' or i=='(' or i==')':\n",
    "            chars = chars + 1\n",
    "    return chars/url_len\n",
    "df['Special_char_ratio']= df['urls'].apply(lambda i: spl_char_ratio(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf99ca9",
   "metadata": {},
   "source": [
    "# Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "121a95eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_ratio(url):\n",
    "    url_len = len(str(url))\n",
    "    nums = 0\n",
    "    for i in url:\n",
    "        if i>='0' and i<='9':\n",
    "            nums = nums + 1\n",
    "    return (nums/url_len)\n",
    "df['numbers_ratio_inURL']= df['urls'].apply(lambda i: number_ratio(i))\n",
    "\n",
    "def number_URL(url):\n",
    "    nums = 0\n",
    "    for i in url:\n",
    "        if i>='0' and i<='9':\n",
    "            nums = nums + 1\n",
    "    return (nums)\n",
    "df['numbers_inURL']= df['urls'].apply(lambda i: number_URL(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395d8201",
   "metadata": {},
   "source": [
    "# Alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8536018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphabet_ratio(url):\n",
    "    url_len = len(str(url))\n",
    "    letters = 0\n",
    "    for i in url:\n",
    "        if i.isalpha():\n",
    "            letters = letters + 1\n",
    "    return (letters/url_len)\n",
    "df['alphabet_ratio_inURL']= df['urls'].apply(lambda i: alphabet_ratio(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c2922c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "from math import log\n",
    "from string import ascii_lowercase\n",
    "\n",
    "from tld import get_tld\n",
    "\n",
    "def fd_length(url):\n",
    "    urlpath= urlparse(url).path\n",
    "    try:\n",
    "        return len(urlpath.split('/')[1])\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "df['fd_length'] = df['urls'].apply(lambda i: fd_length(i))\n",
    "df['fd_length2'] = df['urls'].apply(lambda i: fd_length(i))\n",
    "\n",
    "df['tld'] = df['urls'].apply(lambda i: get_tld(i,fail_silently=True))\n",
    "def tld_length(tld):\n",
    "    try:\n",
    "        return len(tld)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "df['tld_length'] = df['tld'].apply(lambda i: tld_length(i))\n",
    "df['tld_length2'] = df['tld'].apply(lambda i: tld_length(i))\n",
    "\n",
    "\n",
    "del df['tld']\n",
    "\n",
    "def has_server_in_string(url):\n",
    "    if 'server' in url.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['has_server'] = df['urls'].apply(lambda i: has_server_in_string(i))\n",
    "\n",
    "def has_login_in_string(url):\n",
    "    if 'login' in url.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['has_login'] = df['urls'].apply(lambda i: has_login_in_string(i))\n",
    "\n",
    "def has_client_in_string(url):\n",
    "    if 'client' in url.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['has_client'] = df['urls'].apply(lambda i: has_client_in_string(i))\n",
    "\n",
    "def has_admin_in_string(url):\n",
    "    if 'admin' in url.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['has_admin'] = df['urls'].apply(lambda i: has_admin_in_string(i))\n",
    "\n",
    "def no_of_dir(url):\n",
    "    urldir = urlparse(url).path\n",
    "    return urldir.count('/')\n",
    "df['count_dir'] = df['urls'].apply(lambda i: no_of_dir(i))\n",
    "df['count_dir2'] = df['urls'].apply(lambda i: no_of_dir(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "525869d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortening_service(url):\n",
    "    match = re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n",
    "                      'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n",
    "                      'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n",
    "                      'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n",
    "                      'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n",
    "                      'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n",
    "                      'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|'\n",
    "                      'tr\\.im|link\\.zip\\.net',\n",
    "                      url)\n",
    "    if match:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "df['short_url'] = df['urls'].apply(lambda i: shortening_service(i))\n",
    "df['short_url2'] = df['urls'].apply(lambda i: shortening_service(i))\n",
    "df['short_url3'] = df['urls'].apply(lambda i: shortening_service(i))\n",
    "\n",
    "\n",
    "def number_subdomain(url):\n",
    "    count = 0\n",
    "    domain = urlparse(url).netloc\n",
    "    dom = '.'.join(domain.split('.')[:-2])\n",
    "    for i in dom:\n",
    "        if i=='.':\n",
    "            count = count+1\n",
    "    return (count-1)\n",
    "\n",
    "df['number_subdom'] = df['urls'].apply(lambda i: number_subdomain(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b9f758",
   "metadata": {},
   "source": [
    "# importing libraries for domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0dcf6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "from math import log\n",
    "from string import ascii_lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec40a53",
   "metadata": {},
   "source": [
    "# domain features (lexical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c729f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_len(url):\n",
    "    domain = urlparse(str(url)).netloc\n",
    "    return len(domain)\n",
    "df['domain_length']= df['urls'].apply(lambda i: domain_len(i))\n",
    "\n",
    "def dom(url):\n",
    "    return (urlparse(str(url)).netloc)\n",
    "df['domain_name'] = df['urls'].apply(lambda i: dom(i))\n",
    "df['dots_in_domain'] = df['domain_name'].apply(lambda i: i.count('.'))\n",
    "df['hyphens_in_domain'] = df['domain_name'].apply(lambda i: i.count('-'))\n",
    "\n",
    "del df['domain_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ad829df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['url_type'] = df['type'].apply(lambda i: i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "048e8049",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['type']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf708bf",
   "metadata": {},
   "source": [
    "# Saving the dataset as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7372d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'D:/SASTRA_UNIVERSITY/Mini_Project/testing1.csv')\n",
    "df_clean = df.loc[:,['ip_in_URL','random_words','avg_len_random_words','english_words','avg_len_english_words','http_in_URL','semicolon_in_URL','AND_in_URL','URL_length','alphabets_in_URL','uppercase_letters_inURL','lowercase_letters_inURL','uppercase_letters_ratio_inURL','lowercase_letters_ratio_inURL','Special_char_in_URL','numbers_ratio_inURL','alphabet_ratio_inURL','fd_length','fd_length2','tld_length','tld_length2','has_server','has_login','has_client','has_admin','count_dir','count_dir2','domain_length','dots_in_domain','short_url','short_url2','short_url3','number_subdom','hyphens_in_domain','url_type']]\n",
    "df_clean.to_csv(r'D:/SASTRA UNIVERSITY/Mini_Project/testing2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b451f47",
   "metadata": {},
   "source": [
    "# SelectK best algorithm for feature reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1af43aae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This SelectKBest instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      7\u001b[0m selector \u001b[38;5;241m=\u001b[39m SelectKBest(chi2,k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m selected_cols \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns[\u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(selected_cols)\n",
      "File \u001b[1;32md:\\sastra university\\program files\\python compiler\\lib\\site-packages\\sklearn\\feature_selection\\_base.py:53\u001b[0m, in \u001b[0;36mSelectorMixin.get_support\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_support\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    Get a mask, or integer index, of the features selected.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m        values are indices into the input feature vector.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_support_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mask \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indices \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mwhere(mask)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32md:\\sastra university\\program files\\python compiler\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:674\u001b[0m, in \u001b[0;36mSelectKBest._get_support_mask\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_support_mask\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 674\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    677\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscores_\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n",
      "File \u001b[1;32md:\\sastra university\\program files\\python compiler\\lib\\site-packages\\sklearn\\utils\\validation.py:1345\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1340\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1341\u001b[0m         v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1342\u001b[0m     ]\n\u001b[0;32m   1344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted:\n\u001b[1;32m-> 1345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This SelectKBest instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "data = pd.read_csv(r'D:/SASTRA_UNIVERSITY/Mini_Project/testing1.csv')\n",
    "X = data.iloc[:, 2:-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "\n",
    "selector = SelectKBest(chi2,k=20)\n",
    "\n",
    "\n",
    "selected_cols = X.columns[selector.get_support()]\n",
    "\n",
    "print(selected_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6faae8e",
   "metadata": {},
   "source": [
    "# Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f38128",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_of_interest = ['underscore','//','@','https','hash','numbers_inURL','Special_char_ratio']\n",
    "corr_matrix = df.corr()\n",
    "co_mat = corr_matrix.loc[:,:]\n",
    "co_mat_clean = corr_matrix.loc[:,cols_of_interest]\n",
    "\n",
    "co_mat.to_csv('D:\\SASTRA UNIVERSITY\\Mini_Project\\correlation_unclean.csv')\n",
    "co_mat_clean.to_csv('D:\\SASTRA UNIVERSITY\\Mini_Project\\correlation_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f6da2d",
   "metadata": {},
   "source": [
    "# Plotting heat maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4986aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(co_mat, cmap='YlGnBu')\n",
    "\n",
    "plt.title('27x27')\n",
    "plt.xlabel('X-axis label')\n",
    "plt.ylabel('Y-axis label')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(co_mat_clean, cmap='YlGnBu')\n",
    "\n",
    "plt.title('27x7')\n",
    "plt.xlabel('X-axis label')\n",
    "plt.ylabel('Y-axis label')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
